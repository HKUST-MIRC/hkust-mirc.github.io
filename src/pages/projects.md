---
title: 'Ongoing Projects'
layout: '~/layouts/MarkdownLayoutWithToggle.astro'
---

_Last updated_: November 11, 2025

<details>
<summary><strong>AIS Support Fund for Interdisciplinary Research Collaboration</strong>, "A Scalable Framework for Responsible AIGC Governance and Innovation", 2025-2026.</summary>

**Project Overview**:
This project tackles the risks of AI-generated content (AIGC) by developing a multi-level governance framework. It will create a taxonomy to categorize AIGC risks like deepfakes and algorithmic biases, using empirical analysis and expert interviews to identify high-risk scenarios.

The project will explore AIGC’s impact on public trust and media credibility through case studies. It will co-design technical solutions, such as explainability tools and content detection systems and integrate them into media workflows. Governance efforts will include creating the Hong Kong AIGC Risk Database, evaluating standards through adversarial testing, and developing policy toolkits informed by global governance models. The project aims to deliver a scalable framework for responsible AIGC innovation.

**Principal Investigator**: Celine Yunya SONG (HKUST)

**Collaborators**: Janet Hsiao (HKUST), Masaru Yarime (HKUST), Yangqiu Song (HKUST)

</details>

<details>

<summary><strong>SBM Strategic Fund for Futuristic Business Research</strong>, "Generative Artificial Intelligence as a Cognitive Partner for Human Responders", 2025-2027.</summary>

**Project Overview**:
This project pioneers a new paradigm for human–AI interaction by reframing Generative AI (GenAI) as a cognitive partner rather than a content generator. Instead of producing text on behalf of users, GenAI engages them in AI-mediated meta-communication—a reflective process that prompts clarification, elaboration, and refinement of thought. Through this interaction, individuals learn to express their ideas with greater clarity, specificity, and persuasiveness.

The study moves beyond traditional single-domain experiments by adopting a multi-domain, multi-level experimental framework. Each experiment situates GenAI in a distinct communicative context—such as personal feedback, career advising, economic forecasting, journalism, and gendered self-promotion—to examine how AI scaffolds human reasoning across diverse cognitive demands, levels of expertise, and communication asymmetries. This comparative design enables a deeper understanding of how AI can support human cognition in varied real-world situations.

Methodologically, the project introduces several innovations. A proof-of-concept pipeline integrates real-time AI prompts into open-ended responses, followed by behavioral and perceptual evaluations by external raters. Hybrid evaluation metrics combine linguistic algorithms (e.g., clarity, concreteness) with behavioral outcomes (e.g., forecast accuracy, writing quality) and user experience data (e.g., effort, satisfaction). Cross-domain experimentation operationalizes the “AI-as-partner” model across contexts, while an equity testing framework examines how AI-mediated reflection shapes self-promotion behaviors across gender, yielding both theoretical and policy-relevant insights.

By conceptualizing AI as a meta-communicator—an active co-thinker that enhances reasoning and reflection—this project redefines the boundaries of communication science and human–AI collaboration. Its open-source tools and evaluation rubrics will inform the design of AI-enhanced education, journalism, and policymaking interfaces, advancing a more reflective, equitable, and human-centered AI future.

**Investigators**: David Hagmann (PI, HKUST), Yang Lu (Co-PI, HKUST), Celine Yunya Song (Co-PI, HKUST), and George Loewenstein (Co-PI, Carnegie Mellon University)

</details>
