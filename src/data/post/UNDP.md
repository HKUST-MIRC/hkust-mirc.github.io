---
publishDate: 2026-01-08T00:00:00Z
title: 'MIRC Director Prof. Song Yunya Discusses Institutional Governance on the Policy Dialogue on AI as a Driver for Human and “High-quality” Development at UNDP Beijing'
except: The Media Intelligence Research Center (MIRC) joined global leaders at the UN Building in Beijing to explore how artificial intelligence can empower sustainable human development and bridge the global digital divide through responsible governance.
image: ~/assets/images/events/UNDP2026/640.webp
tags:
  - AI Governance
  - Human Development
  - UNDP
  - MIRC
---

_Professor Song Yunya, Director of the Media Intelligence Research Center (MIRC), shares insights on institutional governance at the Policy Dialogue on AI as a Driver for Human and “High-quality” Development._

## Useful Links:

- [Event on UNDP China Website](https://www.undp.org/china/press-releases/ai-driven-high-quality-human-https://www.undp.org/china/speeches/remarks-ms-beate-trankmann-policy-dialogue-ai-driver-human-and-high-quality-development)
- [Event Summary on UNDP China WeChat(Chinese)](https://mp.weixin.qq.com/s/LNdmDxsbFXpuifIdzorkaQ?scene=1)

## Event Overview

On January 5, 2026, the **Policy Dialogue on AI as a Driver for Human and “High-quality” Development** was successfully held at the United Nations Building in Beijing. Co-hosted by the **United Nations Development Programme (UNDP) China** and the **Institute for AI International Governance of Tsinghua University**, the forum convened leaders from government, academia, and industry to discuss AI’s role in global governance, economic growth, and social inclusion.

## Professor Song Yunya and MIRC's Vision

![image](~/assets/images/events/UNDP2026/image.png)
**Professor Song Yunya**, the **Director of the HKUST Media Intelligence Research Center (MIRC)**, was a key contributor to the "Legislation and Governance" session. Representing MIRC's mission to pioneer media intelligence for society, Professor Song addressed the critical issue of "structural capability differentiation" caused by AI.

From a governance perspective, Professor Song Yunya proposed that the development of artificial intelligence is triggering a structural "capability differentiation." This differentiation is not primarily reflected at the level of technical access, but rather in whether various social actors possess the institutional capacity to understand AI outputs, evaluate their appropriateness, and make corrections when necessary. She pointed out that when this capacity is unevenly distributed, AI may inadvertently solidify or even amplify existing inequalities, even while "operating normally."

Therefore, the key to promoting inclusive and responsible AI lies not in proposing more principles, but in establishing institutional governance mechanisms that are operational, accountable, and corrigible. Regarding this issue, she introduced research methodologies centered on institutional process tracking, governance mechanism mapping, interpretive effect testing, and feedback error-correction analysis.
